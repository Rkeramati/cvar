{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 856,
   "metadata": {},
   "outputs": [],
   "source": [
    "nS = 20\n",
    "nA = 4\n",
    "alpha=0.25\n",
    "N=100\n",
    "dz = (50 + 50)/(50)\n",
    "z = np.arange(51) * dz - 50\n",
    "p = np.random.rand(nS, nA, 51)\n",
    "sums = p.sum(axis = -1)\n",
    "p = p/sums[:, :, np.newaxis]\n",
    "count = np.random.randint(low=1, high=100, size=(nS, nA))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 857,
   "metadata": {},
   "outputs": [],
   "source": [
    "def CVaRoptNorm(x, p, count, z, alpha, c=0.1, N=20, bonus=None):\n",
    "    # x is array of size [n_samples, 1]\n",
    "    batchsize = x.shape[0]\n",
    "    \n",
    "    Q = np.zeros((batchsize, nA))\n",
    "    for s in range(batchsize):\n",
    "        for a in range(nA):\n",
    "            # Apply Optimism\n",
    "            if count is not None:\n",
    "                cdf = np.cumsum(p[x[s], a, :]) - c/np.sqrt(count[x[s], a])\n",
    "            cdf = np.clip(cdf, a_min=0, a_max=None)\n",
    "            cdf[-1] = 1 #Match the last one to 1\n",
    "            # Compute CVaR\n",
    "            cdf = np.tile(cdf, N).reshape(N, 51)\n",
    "            tau = np.random.uniform(0, alpha, N).reshape(N, 1)\n",
    "            idx = np.argmax((cdf > tau) * 1.0, axis=1)\n",
    "            # Average\n",
    "            values = z[idx]\n",
    "            Q[s, a] = np.mean(values)\n",
    "    return Q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 869,
   "metadata": {},
   "outputs": [],
   "source": [
    "def CVaRoptA(x, p, count, z, alpha, c=0.1, N=20, bonus=None):\n",
    "    # x is array of size [n_samples, 1]\n",
    "    batchsize = x.shape[0]\n",
    "    \n",
    "    Q = np.zeros((batchsize, nA))\n",
    "    for a in range(nA):\n",
    "        # Apply Optimism\n",
    "        if count is not None:\n",
    "            cdf = np.cumsum(p[x, a, :], axis=-1) - np.expand_dims(c/np.sqrt(count[x, a]), axis=-1)  \n",
    "        else:\n",
    "            cdf = np.cumsum(p[x, a, :], axis=-1) - bonus\n",
    "        cdf = np.clip(cdf, a_min=0, a_max=None)\n",
    "        cdf[:, -1] = 1 #Match the last one to 1\n",
    "        # Compute CVaR\n",
    "        tau = np.expand_dims(np.random.uniform(0, alpha, N).reshape(N, 1), axis = 0)\n",
    "        #cdf = np.tile(cdf, N).reshape(batchsize, N, 51)\n",
    "        cdf = np.expand_dims(cdf, axis = 1)\n",
    "        idx = np.argmax((cdf > tau) * 1.0, axis=-1)\n",
    "        # Average\n",
    "        values = z[idx]\n",
    "        Q[:, a] = np.mean(values, axis=-1)\n",
    "    return Q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 870,
   "metadata": {},
   "outputs": [],
   "source": [
    "def CVaRopt(x, p, count, z, alpha, c=0.1, N=20, bonus=None):\n",
    "    # x is array of size [n_samples, 1]\n",
    "    batchsize = x.shape[0]\n",
    "    \n",
    "    Q = np.zeros((batchsize, nA))\n",
    "    if count is not None:\n",
    "        cdf = np.cumsum(p[x, :, :], axis=-1) - np.expand_dims(c/np.sqrt(count[x, :]), axis=-1)\n",
    "    \n",
    "    \n",
    "    cdf = np.clip(np.squeeze(cdf), a_min=0, a_max=1)\n",
    "    cdf[:, :, -1] = 1 #Match the last one to 1\n",
    "    tau = np.random.uniform(0, alpha, N)\n",
    "    cdf = np.expand_dims(cdf, axis = -1)\n",
    "    idx = np.argmax((cdf > tau[np.newaxis,np.newaxis,np.newaxis,:]) * 1.0, axis=-2)\n",
    "\n",
    "    values = z[idx]\n",
    "    Q[:, :] = np.mean(values, axis=-1)\n",
    "    \n",
    "#     for a in range(nA):\n",
    "#         # Apply Optimism\n",
    "#         #print(np.cumsum(p[x, a, :], axis=-1).shape)\n",
    "#         #print((c/np.sqrt(count[x, a])).shape)\n",
    "#         if count is not None:\n",
    "#             cdf = np.cumsum(p[x, a, :], axis=-1) - np.expand_dims(c/np.sqrt(count[x, a]), axis=-1)\n",
    "        \n",
    "        \n",
    "        \n",
    "#         # Compute CVaR\n",
    "#         tau = np.expand_dims(np.random.uniform(0, alpha, N).reshape(N, 1), axis = 0)\n",
    "#         #cdf = np.tile(cdf, N).reshape(batchsize, N, 51)\n",
    "#         cdf = np.expand_dims(cdf, axis = 1)\n",
    "#         idx = np.argmax((cdf > tau) * 1.0, axis=-1)\n",
    "#         # Average\n",
    "\n",
    "    return Q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 871,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 44.32  -9.06 -15.38 -19.22]\n",
      " [ 13.5   -1.38  -7.16   3.22]\n",
      " [-14.5  -10.98  -1.68 -17.92]\n",
      " ...\n",
      " [-14.5  -10.98  -1.68 -17.92]\n",
      " [ 41.78  50.   -19.28  -9.12]\n",
      " [ -8.38  -3.88 -12.6   -8.48]]\n",
      "1.1451525688171387\n"
     ]
    }
   ],
   "source": [
    "x = np.array([0, 2, 4, 6, 8]*1000)\n",
    "start = time.time()\n",
    "print(CVaRopt(x, p, count, z, alpha, c=2, N=N))\n",
    "end = time.time()\n",
    "print(end - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 872,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[50. 50. 50. 50.]\n",
      " [50. 50. 50. 50.]\n",
      " [50. 50. 50. 50.]\n",
      " ...\n",
      " [50. 50. 50. 50.]\n",
      " [50. 50. 50. 50.]\n",
      " [50. 50. 50. 50.]]\n",
      "0.6737716197967529\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "print(CVaRoptA(x, p, count, z, alpha, c=20, N=N)) # best\n",
    "end = time.time()\n",
    "print(end - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = time.time()\n",
    "print(CVaRoptNorm(x, p, count, z, alpha, c=20, N=N))\n",
    "end = time.time()\n",
    "print(end - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 807,
   "metadata": {},
   "outputs": [],
   "source": [
    "def observe_old(x, a, r, nx, terminal, lr, bonus, p, z, ifCVaR=True):\n",
    "    dz = 2\n",
    "    # Choose the optimal action a*\n",
    "    if not ifCVaR: #Normal\n",
    "        Q_nx = np.sum(p[nx, :, :] * z, axis=1)\n",
    "        a_star = np.argmax(Q_nx)\n",
    "    else: # take the argmax of CVaR\n",
    "        Q_nx = CVaRoptA(x, p, None, z, 0.25, N=N, bonus=bonus)\n",
    "        a_star = np.argmax(Q_nx)\n",
    "\n",
    "    m = np.zeros(51) #target distribution\n",
    " \n",
    "    if not terminal:\n",
    "        # Apply Optimism:\n",
    "        cdf = np.cumsum(p[nx, a_star, :]) - bonus\n",
    "        cdf = np.clip(cdf, a_min=0, a_max=1) # Set less than 0 to 0\n",
    "        cdf[-1] = 1 #set the last to be equal to 1\n",
    "        cdf[1:] -= cdf[:-1]\n",
    "        optimistic_pdf = cdf # Set the optimisitc pdf\n",
    " \n",
    "        # Distribute the probability mass\n",
    "        tz = np.clip(r + 0.95*z,\\\n",
    "                     -50, 50)\n",
    "        b = (tz - -50)/dz\n",
    "        l = np.floor(b).astype(np.int32); u = np.ceil(b).astype(np.int32)\n",
    "\n",
    "        idx = np.arange(51)\n",
    "        m[l] += optimistic_pdf[idx] * (u-b)\n",
    "\n",
    "        m[u] += optimistic_pdf[idx] * (b-l)\n",
    "             # taking into account when l == u\n",
    "             # will be zero for l<b and 1 for l==b\n",
    "        #print(np.floor((1 + (l-b))))\n",
    "        #m[idx] += optimistic_pdf[idx] * np.floor((1 + (l-b)))\n",
    "        # Terminal State:\n",
    "    else:\n",
    "        print('here')\n",
    "        tz = np.clip(r, -50, 50)\n",
    "        b = (tz - -50)/dz\n",
    "        l = int(np.floor(b)); u = int(np.ceil(b))\n",
    "        if l == u:\n",
    "            m[l] = 1\n",
    "        else:\n",
    "            m[l] = (u-b)\n",
    "            m[u] = (b-l)\n",
    "    return m\n",
    " #         # Learning with learning rate\n",
    " #         self.p[x, a, :] = self.p[x, a, :] + lr * (m - self.p[x, a, :])\n",
    " #         # Map back to a probability distribtuion, sum = 1\n",
    " #         self.p[x, a, :] /= np.sum(self.p[x, a, :])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 840,
   "metadata": {},
   "outputs": [],
   "source": [
    "def observe_mid(x, a, r, nx, terminal, lr, bonus, p, z, ifCVaR=True):\n",
    "    dz = 2\n",
    "    # Choose the optimal action a*\n",
    "    batchsize = x.shape[0]\n",
    "    if not ifCVaR: #Normal\n",
    "        Q_nx = np.sum(p[nx, :, :] * z, axis=-1)\n",
    "        a_star = np.argmax(Q_nx, axis=-1)\n",
    "    else: # take the argmax of CVaR\n",
    "        Q_nx = CVaRoptA(x, p, None, z, 0.25, N=N, bonus=bonus)\n",
    "        a_star = np.argmax(Q_nx, axis=-1)\n",
    "    \n",
    "\n",
    "    m = np.zeros((batchsize, 51)) #target distribution\n",
    "    for bb in range(batchsize):\n",
    "        if not terminal[bb]:\n",
    "            # Apply Optimism:\n",
    "            cdf = np.cumsum(p[nx[bb], a_star[bb], :]) - bonus\n",
    "            cdf = np.clip(cdf, a_min=0, a_max=1) # Set less than 0 to 0\n",
    "            cdf[-1] = 1 #set the last to be equal to 1\n",
    "            cdf[1:] -= cdf[:-1]\n",
    "            optimistic_pdf = cdf # Set the optimisitc pdf\n",
    "\n",
    "            # Distribute the probability mass\n",
    "            tz = np.clip(r[bb] + 0.95*z,\\\n",
    "                         -50, 50)\n",
    "            b = (tz - -50)/dz\n",
    "            l = np.floor(b).astype(np.int32); u = np.ceil(b).astype(np.int32)\n",
    "\n",
    "            idx = np.arange(51)\n",
    "            m[bb, l] += optimistic_pdf[idx] * (u-b)\n",
    "\n",
    "            m[bb, u] += optimistic_pdf[idx] * (b-l)\n",
    "                 # taking into account when l == u\n",
    "                 # will be zero for l<b and 1 for l==b\n",
    "            #print(np.floor((1 + (l-b))))\n",
    "            #m[idx] += optimistic_pdf[idx] * np.floor((1 + (l-b)))\n",
    "            # Terminal State:\n",
    "        else:\n",
    "            print('here')\n",
    "            tz = np.clip(r, -50, 50)\n",
    "            b = (tz - -50)/dz\n",
    "            l = int(np.floor(b)); u = int(np.ceil(b))\n",
    "            if l == u:\n",
    "                m[bb, l] = 1\n",
    "            else:\n",
    "                m[bb, l] = (u-b)\n",
    "                m[bb, u] = (b-l)\n",
    "    return np.mean(m, axis=0)\n",
    " #         # Learning with learning rate\n",
    " #         self.p[x, a, :] = self.p[x, a, :] + lr * (m - self.p[x, a, :])\n",
    " #         # Map back to a probability distribtuion, sum = 1\n",
    " #         self.p[x, a, :] /= np.sum(self.p[x, a, :])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 851,
   "metadata": {},
   "outputs": [],
   "source": [
    "def observe(x, a, r, nx, terminal, lr, bonus, p, z, ifCVaR=True):\n",
    "    #dz = 2\n",
    "    # Choose the optimal action a*\n",
    "    batchsize = x.shape[0]\n",
    "    if not ifCVaR: #Normal\n",
    "        Q_nx = np.sum(p[nx, :, :] * z, axis=-1)\n",
    "        a_star = np.argmax(Q_nx, axis=-1)\n",
    "    else: # take the argmax of CVaR\n",
    "        Q_nx = CVaRoptA(x, p, None, z, 0.25, N=N, bonus=bonus)\n",
    "        a_star = np.argmax(Q_nx, axis=-1)\n",
    "    \n",
    "    m = np.zeros((batchsize, 51)).flatten() #target distribution\n",
    "    #m = np.random.rand(batchsize, 51)\n",
    "    cdf = np.cumsum(p[nx, a_star, :], axis=-1) - bonus\n",
    "    cdf = np.clip(cdf, a_min=0, a_max=1) # Set less than 0 to 0\n",
    "    cdf[:, -1] = 1 #set the last to be equal to 1\n",
    "    cdf[:, 1:] -= cdf[:, :-1]\n",
    "    optimistic_pdf = cdf # Set the optimisitc pdf\n",
    "    #print(optimistic_pdf.shape)\n",
    "    # Distribute the probability mass\n",
    "    T = terminal[:, np.newaxis].astype(np.int32)\n",
    "    \n",
    "    tz = np.clip(r[:, np.newaxis] + 0.95*z[np.newaxis, :] * (1-T),\\\n",
    "                 -50, 50)\n",
    "    b = (tz - -50)/dz\n",
    "    l = np.floor(b).astype(np.int32); u = np.ceil(b).astype(np.int32)\n",
    "    idx = np.arange(51)\n",
    "    #print(np.bincount(l.flatten()))\n",
    "    bbbbb = np.arange(batchsize)[:, np.newaxis]\n",
    "    l_idx = (51 * bbbbb + l).flatten()\n",
    "    \n",
    "    #print(l_idx)\n",
    "    m[l_idx] += (((1-T) * optimistic_pdf[:, idx] +\\\n",
    "            T) * (u-b)).flatten()\n",
    "    \n",
    "    u_idx =  (51 * np.arange(batchsize)[:, np.newaxis] + u).flatten()\n",
    "    m[u_idx] += (((1-T) * optimistic_pdf[:, idx] +\\\n",
    "            T) * (b-l)).flatten()\n",
    "    m = m.reshape(batchsize, 51)\n",
    "    # taking into account when l == u\n",
    "    # will be zero for l<b and 1 for l==b\n",
    "    #m[np.tile(idx, batchsize).flatten()] += (((1-terminal)[:, np.newaxis] * optimistic_pdf[:, idx] +\\\n",
    "    #        terminal.astype(np.int32)[:, np.newaxis]) * np.floor((1 + (l-b)))).flatten()\n",
    "    m = np.mean(m ,axis = 0)\n",
    "    return m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 852,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7.891872882843018\n",
      "10.825649976730347\n",
      "25.832557916641235\n",
      "0.015285833235971907\n",
      "0.012301073612616687\n"
     ]
    }
   ],
   "source": [
    "sss = 10000\n",
    "x = np.array([0, 2, 4, 6, 8]*sss); a=np.array([0, 1, 2, 1, 3]*sss); r=np.array([0.2, 0.2, -1.2, -1.2, -5.2]*sss)\n",
    "terminal = np.array([False, False, False, False, False]*sss)\n",
    "#x=np.array([5, 4]); a=np.array([2, 1]); r=np.array([0.2, 0.2]); terminal=np.array([False, False])\n",
    "start = time.time()\n",
    "mm = observe(x, a, r, x+1, terminal, 0.001, 0.1, p, z)\n",
    "end = time.time()\n",
    "print(end-start)\n",
    "\n",
    "start = time.time()\n",
    "mmm = observe_mid(x, a, r, x+1, terminal, 0.001, 0.1, p, z)\n",
    "end = time.time()\n",
    "print(end-start)\n",
    "\n",
    "m = np.zeros((5*sss, 51))\n",
    "start = time.time()\n",
    "for i in range(5*sss):\n",
    "    m[i, :]= observe_old(x[i, np.newaxis], a[i, np.newaxis], r[i, np.newaxis],\\\n",
    "                x[i, np.newaxis]+1, terminal[i, np.newaxis], 0.001, 0.1, p, z)\n",
    "end = time.time()\n",
    "print(end-start)\n",
    "#print(np.mean(m, axis=0))\n",
    "print(np.linalg.norm(mm - np.mean(m, axis=0), 2))\n",
    "print(np.linalg.norm(mmm - np.mean(m, axis=0), 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 782,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 2, 1, 1])"
      ]
     },
     "execution_count": 782,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.bincount([0, 1, 1, 2, 3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 741,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = np.random.rand(2, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 855,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.388888888888889"
      ]
     },
     "execution_count": 855,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "25.8/10.8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 853,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.307692307692308"
      ]
     },
     "execution_count": 853,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "25.8/7.8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "        \n",
    "     '''\n",
    "         m = np.zeros(self.config.nAtoms) #target distribution\n",
    " \n",
    "         if not terminal:\n",
    "             # Apply Optimism:\n",
    "             cdf = np.cumsum(self.p[nx, a_star, :]) - bonus\n",
    "             cdf = np.clip(cdf, a_min=0, a_max=1) # Set less than 0 to 0\n",
    "             cdf[-1] = 1 #set the last to be equal to 1\n",
    "             cdf[1:] -= cdf[:-1]\n",
    "             optimistic_pdf = cdf # Set the optimisitc pdf\n",
    " \n",
    "             # Distribute the probability mass\n",
    "             tz = np.clip(r + self.config.gamma * self.z,\\\n",
    "                     self.config.Vmin, self.config.Vmax)\n",
    "             b = (tz - self.config.Vmin)/self.dz\n",
    "             l = np.floor(b).astype(np.int32); u = np.ceil(b).astype(np.int32)\n",
    "             idx = np.arange(self.config.nAtoms)\n",
    " \n",
    "             m[l] += self.p[nx, a_star, idx] * (u-b)\n",
    "             m[u] += self.p[nx, a_star, idx] * (b-l)\n",
    "\n",
    "    # Distribute the probability mass\n",
    "             tz = np.clip(r + self.config.gamma * self.z,\\\n",
    "                     self.config.Vmin, self.config.Vmax)\n",
    "             b = (tz - self.config.Vmin)/self.dz\n",
    "             l = np.floor(b).astype(np.int32); u = np.ceil(b).astype(np.int32)\n",
    "             idx = np.arange(self.config.nAtoms)\n",
    " \n",
    "             m[l] += self.p[nx, a_star, idx] * (u-b)\n",
    "             m[u] += self.p[nx, a_star, idx] * (b-l)\n",
    " \n",
    "             # taking into account when l == u\n",
    "             # will be zero for l<b and 1 for l==b\n",
    "             m[idx] += self.p[nx, a_star, idx] * np.floor((1 + (l-b)))\n",
    "         # Terminal State:\n",
    "         else:\n",
    "             tz = np.clip(r, self.config.Vmin, self.config.Vmax)\n",
    "             b = (tz - self.config.Vmin)/self.dz\n",
    "             l = int(np.floor(b)); u = int(np.ceil(b))\n",
    "             if l == u:\n",
    "                 m[l] = 1\n",
    "             else:\n",
    "                 m[l] = (u-b)\n",
    "                 m[u] = (b-l)\n",
    " \n",
    "         # Learning with learning rate\n",
    "         self.p[x, a, :] = self.p[x, a, :] + lr * (m - self.p[x, a, :])\n",
    "         # Map back to a probability distribtuion, sum = 1\n",
    "         self.p[x, a, :] /= np.sum(self.p[x, a, :])\n",
    "    '''"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
